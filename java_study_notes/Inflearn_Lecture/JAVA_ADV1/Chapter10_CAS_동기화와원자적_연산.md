# 📚 Chapter 10: CAS - 동기화와 원자적 연산

> 📌 공부 날짜: 2025/04/28
> - `JAVA `- 고급 1편
> - `Reference`: 인프런 - 김영한의 실전 자바

---
## ✅ 원자적 연산 소개
- 컴퓨터 과학에서 사용하는 원자적 연산(atomic operation)의 의미는 해당 연산이 더 이상 나눌 수 없는 단위로 수행된다는 것을 의미한다.
- 즉, 원자적 연산은 중단되지 않고, 다른 연산과 간섭 없이 완전히 실행되거나 전혀 실행되지 않는 성질을 가지고 있다.
- 멀티스레드 상황에서 다른 스레드의 간섭 없이 안전하게 처리되는 연산이라는 뜻이다.
```java
int i = 0; // 1. 둘로 쪼갤 수 없는 원자적 연산
i = i + 1; // 2. 원자적 연산이 아니다.
```
- 2번이 원자적 연산이 아닌 이유
  - 오른쪽에 있는 i의 값을 읽는다. i의 값은 0이다.
  - 읽은 0에 1을 더해서 1을 만든다.
  - 더한 1을 왼쪽의 i 변수에 대입한다.
- **원자적 연산은 멀티스레드 상황에서 아무 문제가 발생하지 않는다.**
- **하지만 원자적 연산이 아닌 경우에는 synchronized 블록이나 Lock 등을 사용해서 안전한 임계 영역을 만들어야 한다.**

### 📚 원자적 연산 - AtomicInteger
- 멀티스레드 상황에서 안전하게 증가 연산을 수행할 수 있는 AtomicInteger라는 클래스를 제공한다..

```java
AtomicInteger atomicInteger = new AtomicInteger(0); // 0은 초기값
```
- 다양한 값 증가, 감소 연산을 제공한다. 특정 값을 증가하거나 감소해야 하는데 여러 스레드가 해당 값을 공유해야 한다면, AtomicInteger를 사용하면 된다.
- 🔍참고: AtomicInteger, AtomicLong, AtomicBoolean 등 다양한 AtomicXxx 클래스가 존재한다.

---

### 📚 원자적 연산 - 성능 테스트
1. BasicInteger
    - 일반적인 value++ 사용.
    - 가장 빠르다.
    - CPU 캐시를 적극 사용한다.
    - 안전한 임계 영역도 없고, volatile도 사용하지 않기 때문에 멀티스레드 상황에는 사용하지 않는다.
    - 단일 스레드가 사용하는 경우에 효율적이다.

2. VolatileInteger
    - volatile을 사용해서 CPU 캐시를 사용하지 않고 메인 메모리를 사용한다.
    - 안전한 임계 영역이 없기 때문에 멀티스레드 상황에서 사용할 수 없다.
    - 단일 스레드가 사용하기에는 BasicInteger보다 느리다. 그리고 멀티스레드 상황에서도 안전하지 않다.

3. SyncInteger
    - synchronized를 사용한 안전한 임계 영역이 있기 때문에 멀티스레드 상황에도 안전하게 사용할 수 있다.
    - MyAtomicInteger보다 성능이 느리다.

4. MyAtomicInteger
    - 자바가 제공하는 AtomicInteger를 사용한다. 멀티스레드 상황에 안전하게 사용할 수 있다.
    - 성능도 synchronized, Lock(ReentrantLock)을 사용하는 경우보다 1.5배 ~ 2배 빠르다.
    - SyncInteger처럼 락을 사용하는 경우보다 AtomicInteger가 더 빠른 이유는 락을 사용하지 않기 때문이다.

---

### 📚 CAS 연산 1
- 락 기반 방식의 문제점
  - 락 기반 접근에서는 락을 획득하고 해제하는데 시간이 소요된다.
  - 락을 사용하는 방식은 직관적이지만 상대적으로 무거운 방식이다.

> 🔍 **CAS**
> - 이런 문제를 해결하기 위해 락을 걸지 않고 원자적인 연산을 수행할 수 있는 방법이 있는데, 이것을 CAS(Compare-And-Swap, Compare-And-Set) 연산이라 한다.
> - 이 방법은 락을 사용하지 않기 때문에 락 프리(lock-free) 기법이라 한다.
> - 참고로 CAS 연산은 락을 완전히 대체하는 것은 아니고, 작은 단위의 일부 영역에 적용할 수 있다.
>   - 기본은 락을 사용하고, 특별한 경우에 CAS를 적용할 수 있다고 생각하면 된다.

- compareAndSet(0, 1)
  - AtomicInteger가 가지고 있는 값이 현재 0이면 값은 1로 변경하자는 매우 간단한 메서드이다.
  - 만약 atomicInteger 값이 0이라면 값은 1로 변경되고, true를 반환한다.
  - 값이 0이 아니라면 값은 변경되지 않고, false를 반환한다.
- **여기서 가장 핵심은 이 메서드는 원자적으로 실행된다는 점이다.**
  - 이 메서드가 제공하는 기능이 바로 CAS(Compare-And-Set) 연산이다.

---

### 📚 CPU 하드웨어의 지원
- CAS 연산은 이렇게 원자적이지 않은 두 개의 연산을 CPU 하드웨어 차원에서 특별하게 하나의 원자적인 연산으로 묶어서 제공하는 기능이다.
- 이것은 소프트웨어가 제공하는 기능이 아니라 하드웨어가 제공하는 기능이다.
- 대부분의 현대 CPU들은 CAS 연산을 위한 명령어를 제공한다.

> 🔍 CPU는 다음 두 과정을 묶어서 하나의 원자적인 명령으로 만들어버린다. 따라서 중간에 다른 스레드가 개입할 수 없다.
> 1. x001의 값을 읽는다.
> 2. 읽은 값이 0이면 1로 변경한다.
> - CPU는 두 과정을 하나의 원자적인 명령으로 만들기 위해 1번과 2번 사이에 다른 스레드가 x001의 값을 변경하지 못하게 막는다.

- 두 스레드와 동시에 실행되면서 문제가 발생하는 상황을 스레드가 충돌했다고 표현한다.
- CAS를 사용하는 방식은 충돌이 드물게 발생하는 환경에서는 락을 사용하지 않으므로 높은 성능을 발휘할 수 있다.
- 이는 락을 사용하는 방식과 비교했을 때, 스레드가 락을 획득하기 위해 대기하지 않기 때문에 대기 시간과 오버헤드가 줄어드는 장점이 있다.
- 그러나 충돌이 빈번하게 발생하는 환경에서는 문제가 될 수 있다.
  - 여러 스레드가 자주 동시에 동일한 변수의 값을 변경하려고 시도할 때, CAS는 자주 실패하고 재시도해야 하므로 성능 저하가 발생할 수 있다.
  - 이런 상황에서는 반복문을 계속 돌기 때문에 CPU 자원을 많이 소모하게 된다.

---

### 📚 CAS(Compare-And-Swap)와 락(Lock) 방식의 비교
1. 락(Lock) 방식
    - 비관적(pessimistic) 접근법
    - 데이터에 접근하기 전에 항상 락을 획득
    - 다른 스레드의 접근을 막음.
    - "다른 스레드가 방해할 것이다" 라고 가정.

2. CAS(Compare-And-Swap) 방식
    - 낙관적(optimistic) 접근법
    - 락을 사용하지 않고 데이터에 바로 접근
    - 충돌이 발생하면 그때 재시도
    - "대부분의 경우 충돌이 없을 것이다"라고 가정.

- 간단한 CPU 연산에는 락보다는 CAS를 사용하는 것이 효과적이다.

---

### 📚 CAS 락 구현
- CAS는 단순한 연산뿐만 아니라, 락을 구현하는 데 사용할 수도 있다.
```java
private final AtomicBoolean lock = new AtomicBoolean(false);

public void lock() {
    log("락 획득 시도");
    while (!lock.compareAndSet(false, true)) {
        log("락 획득 실패 - 스핀 대기");
    }
    log("락 획득 완료");
}

public void unLock() {
    lock.set(false);
    log("반납 완료");
}
```
- 원자적인 연산은 스레드 입장에서 쪼갤 수 없는 하나의 연산이다.
  - 따라서 여러 스레드가 동시에 실행해도 안전하다.
  - 이렇게 CAS를 사용해서 원자적인 연산을 만든 덕분에 무거운 동기화 작업 없이 가벼운 락을 만들 수 있었다.
- 동기화 락을 사용하는 경우 스레드가 락을 획득하지 못하면 BLOCKED, WAITING 등으로 상태가 변한다.
  - 그리고 또 대기 상태의 스레드를 깨워야 하는 무겁고 복잡한 과정이 추가로 들어간다.
  - 따라서 성능이 상대적으로 느릴 수 있다.
- 반면에 CAS를 활용한 락 방식은 사실 락이 없다. 단순히 while 문을 반복할 뿐이다.
  - 따라서 대기하는 스레드도 RUNNABLE 상태를 유지하면서 가볍고 빠르게 작동할 수 있다.

---

### 📚 CAS 단점
- 이 방식은 락을 기다리는 스레드가 BLOCKED, WAITING 상태로 빠지지는 않지만, RUNNABLE 상태로 락을 획득할 때까지 while 문을 반복하는 문제가 있다.
  - 따라서 락을 기다리는 스레드가 CPU를 계속 사용하면 대기하는 것이다.
- BLOCKED, WAITING 상태의 스레드는 CPU를 거의 사용하지 않는다.

> ❓ 그럼 어떤 경우에 이런 방식이 효율적일까?
> - 안전한 임계 영역이 필요하지만, 연산이 길지 않고 매우 짧게 끝날 때 사용해야 한다.
>   - ms 이하의 방식만 사용 추천
> - 예를 들어, 숫자 값의 증가. 자료 구조의 데이터 추가와 같이 CPU 사이클이 금방 끝나는 연산에 사용하면 효과적이다.
> - 반면에 데이터베이스의 결과를 대기한다거나, 다른 서버의 요청을 기다린다거나 하는 것처럼 오래 기다리는 작업에 사용하면 CPU를 계속 사용하며 기다리는 최악의 결과가 나올 수도 있다.

> 🔍 스핀 락
> - 스레드가 락이 해제되기를 기다리면서 반복문을 통해 계속해서 확인하는 모습이 마치 제자리에서 회전(spin)하는 것처럼 보인다.
>   - 그래서 이러한 방식을 "스핀 락"이라고도 부른다.
> - 그리고 이런 방식에서 스레드가 락을 획득할 때까지 대기하는 것을 스핀 대기(spin-wait) 또는 CPU 자원을 계속 사용하면서 바쁘게 대기한다고 해서 바쁜 대기(busy-wait)라 한다.

---

## 📌 결론
- 일반적으로 동기화 락을 사용하고, 아주 특별한 경우에 한정해서 CAS를 사용해서 최적화해야 한다.

> 🔍 실무 관점
> - 실무 관점에서 보면 대부분의 애플리케이션들은 공유 자원을 사용할 때, 충돌할 가능성보다 충돌하지 않을 가능성이 훨씬 높다.
> - 우리가 사용하는 많은 자바 동시성 라이브러리들, 동기화 컬렉션들은 성능 최적화를 위해 CAS 연산을 적극 활용한다.
> - 덕분에 실무에서 직접 CAS 연산을 사용하는 일은 매우 드물다.
>   - 대신에 CAS 연산을 사용해서 최적화되어있는 라이브러리들을 이해하고 편리하게 사용할 줄 알면 된다.

---